# fastaFRiP

## Description
This is a pipeline for calculating FRiP ("fraction of reads in peaks") from fasta (or bed + fasta).

## Prerequisites
- python
- Snakemake

## Installation
```
git clone https://github.com/Fudenberg-Research-Group/fastaFRiP.git
cd fastaFRiP/frip_sm
```
## Getting Started

### Downloading fastq data from GEO
FASTQ data is available in the Gene Expression Omnibus (GEO). FASTQ is a common format for storing raw sequencing data generated by next-generation sequencing technologies. In GEO, such raw sequencing data are often included as part of the supplementary files associated with a GEO Series (GSE) record. By clicking on the 'SRA Run Selector', users can select and download specific data (e.g., based on organism, gene, condition, or experiment type) from the Sequence Read Archive (SRA) page.

To quickly access the accession codes of ChIP-seq experiments, you can use the following command:
```
grep "ChIP" SraRunTable.txt | awk -F, '{print $1}' > accession.txt
```
This command extracts the codes for each file, which can later be used to download the necessary data.
We have provided a script, batch_download.sh, to facilitate the data download. However, to run this script, you need to install fasterq-dump in your working conda environment:
```
conda install -c bioconda sra-tools
```
And finally running the script:
```
./batch_download.sh
```

### running the pipeline
You will need to specifiy where your fastq and bowtie index files located, and choose whether to include spike-in normalization procedure, and specify your output directory path in the configuration file `config.yml` (the explanation of each parameter is included in config.yml)

* Tips: To rescale bigwig file and call peaks based on input(control) sample, the pipeline will require a metadata table (stored in .txt file) have the two columns as the below example (column names must be the same as the example), and the sample name should be fetched from the fastq files (e.g. SRR5085155.fastq), and if a sample does not have input, you don't include it in the table:

<center>

|        ChIP|       Input|
|-----------:|-----------:|
| SRR5085155 | SRR5085156 |
| SRR5085157 | SRR5085158 |
</center>

#### generating bam/bed files

Once you set up configuration file, you can run the below command line in the terminal to generate required bam/bed files:

```
snakemake --use-conda --cores $Ncores --configfile config/config.yml
```
You need to make sure there are available computing resource\
  Tips: [Number of cores] * [number of process in config.yml] <= the total number of cpus you have

#### calculating FRiP

After you generate bam files and bed files with the above command line, you can use `calculate_frip.py` to calculate FRiP value.
```
python calculate_frip.py --nproc [number of cpus] [pathway to the metadata table]
```
For example:
```
python calculate_frip.py --nproc 45 /home1/yxiao977/sc1/frip_sm_data/frip_result/Hansen2017/metadata.txt
```
* The metadata.txt should looks like this: each row indicates one comparison pair, and the FRiP value will be concatenated to this metadata table as a column after run calculate_frip.py

<center>

|                BAM|                BED|
|------------------:|------------------:|
| path to bam file1 | path to bed file1 |
| path to bam file2 | path to bed file2 |

</center>

* If you use this snakemake pipeline to process fastq files, then the BAM files you want to use are with the suffix "q30.dedup.bam", and the BED files you want to use are with the suffix ".q30.dedup_peaks.narrowPeak"

## Log
What: Goal would be to have a Pipeline for calculating FRiP ("fraction of reads in peaks") from fasta (or bed + fasta). 

Why: This will be helpful since many experiments share fasta & bed files on GEO, but not many share their bam files (which are need for FRiP).
We would like to compare FRiPs from simulations with a variety of experiments. We can make the rough steps used by the Nora group more reproducible.

Rough steps are:
- bowtie2 alignment --> filtering --> bam generation
- macs2 --> bed peaks --> consensus peaks (+ additional filtering)
- deeptools.countReadsPerBin ( bam, bed) --> FRiP 

Some design questions:
- [ ] what is good test data for developing/testing a pipeline? (e.g. synthetic, or a very small real dataset).
- [ ] how should functions be organized? should snakemake be used or something else? Is the distiller-sm a good template for where to start?

Some todos (list can expand):
- [ ] files to specify requirementsÂ & environment needed
- [ ] options for pipeline to run on regular ChIP or spike-in ChIP data
